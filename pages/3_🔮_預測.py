"""
é æ¸¬é é¢

æä¾›æ¨¡å‹é æ¸¬åŠŸèƒ½ï¼Œæ”¯æ´å–®ç­†è³‡æ–™è¼¸å…¥å’Œ CSV æª”æ¡ˆæ‰¹æ¬¡é æ¸¬ã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
from io import StringIO
from typing import Optional, Dict, Any

from utils.model_manager import load_model, list_models, load_field_info
from utils.data_loader import load_csv_file, validate_dataframe
from utils.prediction_validator import validate_prediction_input
from models.base_model import BaseModel
from utils.data_preprocessor import preprocess_features


def calculate_manual_prediction(model: BaseModel, input_df: pd.DataFrame, target_name: Optional[str] = None) -> Dict[str, Any]:
    """
    æ‰‹å‹•è¨ˆç®—é æ¸¬å€¼ï¼ˆç”¨æ–¼é©—ç®—ï¼‰
    
    Args:
        model: è¨“ç·´å¥½çš„æ¨¡å‹
        input_df: è¼¸å…¥è³‡æ–™ï¼ˆDataFrameï¼‰
        target_name: ç›®æ¨™è®Šæ•¸åç¨±ï¼ˆå¦‚æœæ˜¯å¤šè¼¸å‡ºæ¨¡å‹ï¼‰
    
    Returns:
        dict: åŒ…å«é©—ç®—éç¨‹çš„å­—å…¸
    """
    # ç²å–æ¨¡å‹è³‡è¨Š
    model_info = model.get_info()
    
    # æª¢æŸ¥æ˜¯å¦ç‚ºç·šæ€§å›æ­¸æ¨¡å‹ï¼ˆåªæœ‰ç·šæ€§å›æ­¸å¯ä»¥æ‰‹å‹•é©—ç®—ï¼‰
    if model_info.get('model_name') not in ['Linear Regression', 'Gradient Descent']:
        return {
            'can_calculate': False,
            'message': 'æ­¤æ¨¡å‹é¡å‹ä¸æ”¯æ´æ‰‹å‹•é©—ç®—'
        }
    
    # é è™•ç†è¼¸å…¥è³‡æ–™ï¼ˆèˆ‡é æ¸¬æ™‚ç›¸åŒï¼‰
    if hasattr(model, 'preprocessing_metadata'):
        preprocessing_metadata = model.preprocessing_metadata
        categorical_features = preprocessing_metadata.get('categorical_features', [])
        use_scaling = getattr(model, 'use_scaling', False) if hasattr(model, 'use_scaling') else False
        scaler = getattr(model, 'scaler', None)
        encoder = getattr(model, 'encoder', None)
    else:
        categorical_features = []
        use_scaling = False
        scaler = None
        encoder = None
    
    X_processed, _, _, _ = preprocess_features(
        input_df,
        categorical_features=categorical_features,
        use_scaling=use_scaling,
        fit=False,
        scaler=scaler,
        encoder=encoder
    )
    
    # ç¢ºä¿ç‰¹å¾µé †åºèˆ‡è¨“ç·´æ™‚ä¸€è‡´
    if model.feature_names is not None:
        X_processed = X_processed[model.feature_names]
    
    # ç²å–ä¿‚æ•¸å’Œæˆªè·
    is_multi_output = model_info.get('is_multi_output', False)
    
    if is_multi_output:
        coefficients_list = model_info.get('coefficients', [])
        intercepts_list = model_info.get('intercepts', [])
        target_names = model_info.get('target_names', [])
        
        if target_name is None:
            target_name = target_names[0] if target_names else None
        
        if target_name and target_name in target_names:
            target_idx = target_names.index(target_name)
            coefficients = coefficients_list[target_idx] if target_idx < len(coefficients_list) else []
            intercept = intercepts_list[target_idx] if target_idx < len(intercepts_list) else 0
        else:
            return {
                'can_calculate': False,
                'message': f'æ‰¾ä¸åˆ°ç›®æ¨™è®Šæ•¸ï¼š{target_name}'
            }
    else:
        coefficients = model_info.get('coefficients', [])
        intercept = model_info.get('intercept', 0)
        target_name = model_info.get('target_names', [None])[0]
    
    # æ‰‹å‹•è¨ˆç®—é æ¸¬å€¼
    feature_values = X_processed.iloc[0].values
    manual_prediction = intercept + np.dot(coefficients, feature_values)
    
    # å»ºç«‹é©—ç®—éç¨‹
    calculation_steps = []
    calculation_steps.append(f"**æˆªè·** = {intercept:.6f}")
    
    for i, (feature_name, feature_value) in enumerate(zip(model.feature_names, feature_values)):
        coef = coefficients[i] if i < len(coefficients) else 0
        product = coef * feature_value
        calculation_steps.append(f"**{feature_name}** Ã— {coef:.6f} = {feature_value:.6f} Ã— {coef:.6f} = {product:.6f}")
    
    calculation_steps.append(f"**ç¸½å’Œ** = {manual_prediction:.6f}")
    
    return {
        'can_calculate': True,
        'target_name': target_name,
        'intercept': intercept,
        'coefficients': coefficients,
        'feature_names': model.feature_names,
        'feature_values': feature_values.tolist(),
        'manual_prediction': manual_prediction,
        'calculation_steps': calculation_steps
    }


st.title("ğŸ”® æ¨¡å‹é æ¸¬")
st.markdown("---")

# èªªæ˜æ–‡å­—
st.info(
    "ğŸ‘‹ æ­¡è¿ä½¿ç”¨æ¨¡å‹é æ¸¬åŠŸèƒ½ï¼\n\n"
    "è«‹æŒ‰ç…§ä»¥ä¸‹æ­¥é©Ÿé€²è¡Œé æ¸¬ï¼š\n"
    "1. é¸æ“‡è¦ä½¿ç”¨çš„æ¨¡å‹ï¼ˆè¨“ç·´é é¢çš„æ¨¡å‹æˆ–å·²ä¿å­˜çš„æ¨¡å‹ï¼‰\n"
    "2. é¸æ“‡é æ¸¬æ–¹å¼ï¼ˆå–®ç­†è³‡æ–™æˆ– CSV æ‰¹æ¬¡é æ¸¬ï¼‰\n"
    "3. è¼¸å…¥è³‡æ–™ä¸¦åŸ·è¡Œé æ¸¬\n"
    "4. æŸ¥çœ‹ä¸¦åŒ¯å‡ºé æ¸¬çµæœ"
)

# ========== æ­¥é©Ÿ 1: æ¨¡å‹é¸æ“‡ ==========
st.markdown("### æ­¥é©Ÿ 1: é¸æ“‡æ¨¡å‹")

model: Optional[BaseModel] = None
model_source = None
model_filepath: Optional[str] = None  # è¨˜éŒ„æ¨¡å‹æª”æ¡ˆè·¯å¾‘ï¼ˆå¦‚æœå¾æª”æ¡ˆè¼‰å…¥ï¼‰

# æª¢æŸ¥ session state ä¸­æ˜¯å¦æœ‰è¨“ç·´å¥½çš„æ¨¡å‹
if 'trained_model' in st.session_state and st.session_state['trained_model'] is not None:
    model = st.session_state['trained_model']
    model_source = "session"
    
    st.success("âœ… å·²å¾è¨“ç·´é é¢è¼‰å…¥æ¨¡å‹")
    
    # é¡¯ç¤ºæ¨¡å‹è³‡è¨Š
    model_info = model.get_info()
    col1, col2 = st.columns(2)
    with col1:
        st.write(f"**æ¨¡å‹é¡å‹**ï¼š{model_info.get('model_name', 'Unknown')}")
        st.write(f"**ç›®æ¨™è®Šæ•¸**ï¼š{', '.join(model_info.get('target_names', []))}")
    with col2:
        st.write(f"**ç‰¹å¾µæ•¸é‡**ï¼š{len(model_info.get('feature_names', []))}")
        st.write(f"**å¤šç›®æ¨™**ï¼š{'æ˜¯' if model_info.get('is_multi_output', False) else 'å¦'}")
    
    use_session_model = st.checkbox("ä½¿ç”¨æ­¤æ¨¡å‹", value=True, key="use_session_model")
    
    if not use_session_model:
        model = None
        model_source = None

# å¦‚æœæ²’æœ‰ session state çš„æ¨¡å‹ï¼Œæˆ–ä½¿ç”¨è€…é¸æ“‡ä¸ä½¿ç”¨ï¼Œå‰‡è¼‰å…¥æª”æ¡ˆ
if model is None:
    model_source = "file"
    
    # å–å¾—å·²ä¿å­˜çš„æ¨¡å‹åˆ—è¡¨
    saved_models = list_models()
    
    if not saved_models:
        st.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°å·²ä¿å­˜çš„æ¨¡å‹ã€‚è«‹å…ˆåœ¨è¨“ç·´é é¢è¨“ç·´ä¸¦ä¿å­˜æ¨¡å‹ã€‚")
        st.stop()
    
    # é¡¯ç¤ºæ¨¡å‹é¸æ“‡å™¨
    model_options = {}
    for m in saved_models:
        if 'error' in m:
            display_name = f"{m['filename']} (è¼‰å…¥éŒ¯èª¤)"
        else:
            model_name = m.get('model_name', 'Unknown')
            target_names = ', '.join(m.get('target_names', []))
            modified_time = m.get('modified_time', '').strftime('%Y-%m-%d %H:%M:%S') if m.get('modified_time') else 'Unknown'
            display_name = f"{model_name} | ç›®æ¨™: {target_names} | ä¿å­˜æ™‚é–“: {modified_time}"
        model_options[display_name] = m['filepath']
    
    selected_model_display = st.selectbox(
        "é¸æ“‡å·²ä¿å­˜çš„æ¨¡å‹",
        options=list(model_options.keys()),
        help="é¸æ“‡è¦ä½¿ç”¨çš„æ¨¡å‹æª”æ¡ˆ"
    )
    
    if selected_model_display:
        selected_filepath = model_options[selected_model_display]
        
        # æª¢æŸ¥æ˜¯å¦æœ‰éŒ¯èª¤
        selected_model_info = next((m for m in saved_models if m['filepath'] == selected_filepath), None)
        if selected_model_info and 'error' in selected_model_info:
            st.error(f"âŒ ç„¡æ³•è¼‰å…¥æ¨¡å‹ï¼š{selected_model_info['error']}")
            st.stop()
        
        # è¼‰å…¥æ¨¡å‹
        try:
            with st.spinner("æ­£åœ¨è¼‰å…¥æ¨¡å‹..."):
                model = load_model(selected_filepath)
                model_filepath = selected_filepath  # è¨˜éŒ„æª”æ¡ˆè·¯å¾‘
            
            st.success("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")
            
            # å„ªå…ˆå¾ JSON æª”æ¡ˆè¼‰å…¥æ¬„ä½è³‡è¨Šï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            field_info = load_field_info(selected_filepath)
            if field_info:
                # ä½¿ç”¨ JSON æª”æ¡ˆä¸­çš„è³‡è¨Š
                model_info = field_info
            else:
                # å¦‚æœæ²’æœ‰ JSON æª”æ¡ˆï¼Œå¾æ¨¡å‹å–å¾—è³‡è¨Š
                model_info = model.get_info()
            
            # é¡¯ç¤ºæ¨¡å‹è³‡è¨Š
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**æ¨¡å‹é¡å‹**ï¼š{model_info.get('model_name', 'Unknown')}")
                st.write(f"**ç›®æ¨™è®Šæ•¸**ï¼š{', '.join(model_info.get('target_names', []))}")
            with col2:
                st.write(f"**ç‰¹å¾µæ•¸é‡**ï¼š{len(model_info.get('feature_names', []))}")
                st.write(f"**å¤šç›®æ¨™**ï¼š{'æ˜¯' if model_info.get('is_multi_output', False) else 'å¦'}")
        except Exception as e:
            st.error(f"âŒ è¼‰å…¥æ¨¡å‹å¤±æ•—ï¼š{str(e)}")
            st.stop()

if model is None:
    st.warning("ğŸ‘† è«‹å…ˆé¸æ“‡æ¨¡å‹")
    st.stop()

st.markdown("---")

# ========== æ­¥é©Ÿ 2: é¸æ“‡é æ¸¬æ–¹å¼ ==========
st.markdown("### æ­¥é©Ÿ 2: é¸æ“‡é æ¸¬æ–¹å¼")

prediction_mode = st.radio(
    "é¸æ“‡é æ¸¬æ–¹å¼",
    options=["å–®ç­†è³‡æ–™é æ¸¬", "CSV æª”æ¡ˆæ‰¹æ¬¡é æ¸¬"],
    help="å–®ç­†é æ¸¬é©åˆå¿«é€Ÿæ¸¬è©¦ï¼Œæ‰¹æ¬¡é æ¸¬é©åˆè™•ç†å¤§é‡è³‡æ–™"
)

st.markdown("---")

# ========== æ­¥é©Ÿ 3: åŸ·è¡Œé æ¸¬ ==========
if prediction_mode == "å–®ç­†è³‡æ–™é æ¸¬":
    st.markdown("### æ­¥é©Ÿ 3: è¼¸å…¥è³‡æ–™ä¸¦é æ¸¬")
    
    # å„ªå…ˆå¾ JSON æª”æ¡ˆè¼‰å…¥æ¬„ä½è³‡è¨Šï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    field_info = None
    json_loaded = False
    
    if model_source == "file" and model_filepath:
        # å¦‚æœæ˜¯å¾æª”æ¡ˆè¼‰å…¥çš„æ¨¡å‹ï¼Œå˜—è©¦å¾ JSON æª”æ¡ˆè¼‰å…¥æ¬„ä½è³‡è¨Š
        field_info = load_field_info(model_filepath)
        if field_info:
            json_loaded = True
            st.info(f"âœ… å·²å¾ JSON æª”æ¡ˆè¼‰å…¥æ¬„ä½è³‡è¨Šï¼š{model_filepath.replace('.joblib', '.json')}")
    
    # å¦‚æœæ²’æœ‰ JSON æª”æ¡ˆæˆ–å¾ session state è¼‰å…¥ï¼Œå‰‡å¾æ¨¡å‹å–å¾—è³‡è¨Š
    if field_info is None:
        model_info = model.get_info()
        field_info = {
            'original_columns': model_info.get('original_columns', []),
            'categorical_features': model_info.get('categorical_features', []),
            'numeric_features': model_info.get('numeric_features', []),
            'target_names': model_info.get('target_names', []),
            'feature_names': model_info.get('feature_names', [])
        }
        if model_source == "file" and model_filepath:
            st.warning(f"âš ï¸ æœªæ‰¾åˆ° JSON æª”æ¡ˆï¼Œå¾æ¨¡å‹è¼‰å…¥æ¬„ä½è³‡è¨Šã€‚é æœŸè·¯å¾‘ï¼š{model_filepath.replace('.joblib', '.json')}")
    
    # å¾æ¬„ä½è³‡è¨Šä¸­å–å¾—ç‰¹å¾µé¡å‹è³‡è¨Š
    original_columns = field_info.get('original_columns', [])
    categorical_features = field_info.get('categorical_features', [])
    numeric_features = field_info.get('numeric_features', [])
    target_names = field_info.get('target_names', [])
    feature_names = field_info.get('feature_names', [])
    
    # æ±ºå®šéœ€è¦è¼¸å…¥çš„ç‰¹å¾µï¼ˆå„ªå…ˆä½¿ç”¨ original_columnsï¼Œå¦å‰‡ä½¿ç”¨ feature_namesï¼‰
    if original_columns:
        required_features = original_columns
    else:
        required_features = feature_names
    
    # ç¢ºä¿ç›®æ¨™è®Šæ•¸ä¸æœƒå‡ºç¾åœ¨ç‰¹å¾µåˆ—è¡¨ä¸­ï¼ˆé›–ç„¶ç†è«–ä¸Šä¸æ‡‰è©²å‡ºç¾ï¼‰
    required_features = [f for f in required_features if f not in target_names]
    
    if not required_features:
        st.error("âŒ æ¨¡å‹æ²’æœ‰ç‰¹å¾µè³‡è¨Šï¼Œç„¡æ³•é€²è¡Œé æ¸¬")
        st.stop()
    
    # ç¢ºä¿é¡åˆ¥å‹ç‰¹å¾µå’Œæ•¸å€¼å‹ç‰¹å¾µéƒ½ä¸åŒ…å«ç›®æ¨™è®Šæ•¸
    categorical_features = [f for f in categorical_features if f not in target_names]
    numeric_features = [f for f in numeric_features if f not in target_names]
    
    # å–å¾—é¡åˆ¥å‹ç‰¹å¾µçš„æœ‰æ•ˆå€¼ï¼ˆå¾ encoder ä¸­å–å¾—ï¼‰
    encoder = getattr(model, 'encoder', None)
    valid_categories = {}
    
    # å¦‚æœ encoder å­˜åœ¨ï¼Œèªªæ˜æœ‰é¡åˆ¥å‹ç‰¹å¾µè¢«ç·¨ç¢¼é
    if encoder and hasattr(encoder, 'categories_') and categorical_features:
        # encoder.categories_ çš„é †åºèˆ‡è¨“ç·´æ™‚å‚³å…¥çš„ categorical_features é †åºä¸€è‡´
        # å»ºç«‹ç‰¹å¾µåç¨±åˆ°ç´¢å¼•çš„æ˜ å°„
        preprocessing_metadata = getattr(model, 'preprocessing_metadata', {})
        encoded_feature_names = preprocessing_metadata.get('encoded_feature_names', [])
        
        if encoded_feature_names:
            # å¾ encoded_feature_names å»ºç«‹æ˜ å°„ï¼ˆæ›´å¯é ï¼‰
            # encoded_feature_names çš„é †åºèˆ‡ encoder.categories_ çš„é †åºä¸€è‡´
            seen_features = {}
            for enc_feat in encoded_feature_names:
                underscore_pos = enc_feat.find('_')
                if underscore_pos > 0:
                    orig_feat = enc_feat[:underscore_pos]
                    if orig_feat not in seen_features and orig_feat in categorical_features:
                        # é€™æ˜¯è©²ç‰¹å¾µçš„ç¬¬ä¸€å€‹ç·¨ç¢¼ç‰¹å¾µï¼Œè¨˜éŒ„ç´¢å¼•
                        seen_features[orig_feat] = len(seen_features)
        
            # ä½¿ç”¨æ˜ å°„ä¾†å–å¾—é¡åˆ¥å€¼
            for feature in categorical_features:
                if feature in seen_features:
                    encoder_idx = seen_features[feature]
                    if encoder_idx < len(encoder.categories_):
                        categories = encoder.categories_[encoder_idx]
                        valid_categories[feature] = [str(cat) for cat in categories]
        else:
            # å¦‚æœæ²’æœ‰ encoded_feature_namesï¼Œå˜—è©¦é †åºåŒ¹é…
            for i, feature in enumerate(categorical_features):
                if i < len(encoder.categories_):
                    categories = encoder.categories_[i]
                    valid_categories[feature] = [str(cat) for cat in categories]
    
    # é¡¯ç¤ºèª¿è©¦è³‡è¨Šï¼ˆå¯é¸ï¼Œç”¨æ–¼è¨ºæ–·ï¼‰
    with st.expander("ğŸ” ç‰¹å¾µé¡å‹è¨ºæ–·è³‡è¨Šï¼ˆé»æ“Šå±•é–‹ï¼‰", expanded=False):
        st.write(f"**è³‡æ–™ä¾†æº**ï¼š{'âœ… JSON æª”æ¡ˆ' if json_loaded else 'âš ï¸ æ¨¡å‹ç‰©ä»¶'}")
        if model_source == "file" and model_filepath:
            json_path = model_filepath.replace('.joblib', '.json')
            st.write(f"**JSON æª”æ¡ˆè·¯å¾‘**ï¼š{json_path}")
            from pathlib import Path
            json_file = Path(json_path)
            if json_file.exists():
                st.write(f"**JSON æª”æ¡ˆå­˜åœ¨**ï¼šâœ… æ˜¯")
            else:
                st.write(f"**JSON æª”æ¡ˆå­˜åœ¨**ï¼šâŒ å¦")
        st.write(f"**éœ€è¦è¼¸å…¥çš„ç‰¹å¾µ**ï¼š{len(required_features)} å€‹")
        st.write(f"  - {', '.join(required_features)}")
        st.write(f"**é¡åˆ¥å‹ç‰¹å¾µ**ï¼š{len(categorical_features)} å€‹")
        if categorical_features:
            st.write(f"  - {', '.join(categorical_features)}")
        else:
            st.write("  - ç„¡")
        st.write(f"**æœ‰é¡åˆ¥å€¼çš„ç‰¹å¾µ**ï¼š{len(valid_categories)} å€‹")
        if valid_categories:
            for feat, vals in valid_categories.items():
                st.write(f"  - {feat}: {len(vals)} å€‹é¡åˆ¥å€¼")
        else:
            st.write("  - ç„¡")
        st.write(f"**æ•¸å€¼å‹ç‰¹å¾µ**ï¼š{len(numeric_features)} å€‹")
        if numeric_features:
            st.write(f"  - {', '.join(numeric_features)}")
        else:
            st.write("  - ç„¡")
        st.write(f"**åŸå§‹æ¬„ä½ï¼ˆoriginal_columnsï¼‰**ï¼š{len(original_columns)} å€‹")
        if original_columns:
            st.write(f"  - {', '.join(original_columns)}")
        else:
            st.write("  - ç„¡")
        st.write("**å¾ field_info å–å¾—çš„å®Œæ•´è³‡è¨Šï¼š**")
        st.json(field_info)
    
    # å‹•æ…‹ç”Ÿæˆè¼¸å…¥è¡¨å–®
    input_data = {}
    
    with st.form("single_prediction_form"):
        st.write("**è«‹è¼¸å…¥å„ç‰¹å¾µå€¼ï¼š**")
        
        # åˆ†æˆå…©æ¬„é¡¯ç¤º
        cols = st.columns(2)
        col_idx = 0
        
        for feature in required_features:
            with cols[col_idx % 2]:
                # å„ªå…ˆæª¢æŸ¥ valid_categoriesï¼ˆæœ€å¯é çš„æŒ‡æ¨™ï¼Œå› ç‚ºå®ƒä¾†è‡ª encoderï¼‰
                # å¦‚æœç‰¹å¾µåœ¨ valid_categories ä¸­ï¼Œèªªæ˜å®ƒæ˜¯é¡åˆ¥å‹ç‰¹å¾µ
                if feature in valid_categories:
                    # é¡åˆ¥å‹ç‰¹å¾µä½¿ç”¨ selectbox
                    valid_values = valid_categories[feature]
                    if valid_values:
                        input_data[feature] = st.selectbox(
                            f"{feature} *",
                            options=valid_values,
                            help=f"é¡åˆ¥å‹ç‰¹å¾µï¼Œè«‹é¸æ“‡ä¸€å€‹å€¼"
                        )
                    else:
                        # å¦‚æœæ²’æœ‰æœ‰æ•ˆå€¼åˆ—è¡¨ï¼Œä½¿ç”¨ text_inputï¼ˆæ‡‰è©²ä¸æœƒç™¼ç”Ÿï¼Œä½†ä½œç‚ºå‚™é¸ï¼‰
                        st.warning(f"âš ï¸ ç‰¹å¾µ '{feature}' çš„é¡åˆ¥å€¼è³‡è¨Šä¸å¯ç”¨")
                        input_data[feature] = st.text_input(
                            f"{feature} *",
                            value="",
                            help=f"é¡åˆ¥å‹ç‰¹å¾µï¼Œè«‹è¼¸å…¥å€¼"
                        )
                elif feature in categorical_features:
                    # å¦‚æœä¸åœ¨ valid_categories ä½†åœ¨ categorical_features ä¸­
                    # å¯èƒ½æ˜¯ encoder è³‡è¨Šç¼ºå¤±ï¼Œä½†ä»æ‡‰è¦–ç‚ºé¡åˆ¥å‹
                    st.warning(f"âš ï¸ ç‰¹å¾µ '{feature}' è¢«è­˜åˆ¥ç‚ºé¡åˆ¥å‹ï¼Œä½†é¡åˆ¥å€¼è³‡è¨Šä¸å¯ç”¨")
                    input_data[feature] = st.text_input(
                        f"{feature} *",
                        value="",
                        help=f"é¡åˆ¥å‹ç‰¹å¾µï¼Œè«‹è¼¸å…¥å€¼"
                    )
                else:
                    # æ•¸å€¼å‹ç‰¹å¾µä½¿ç”¨ number_input
                    input_data[feature] = st.number_input(
                        f"{feature} *",
                        value=0.0,
                        format="%.2f",
                        help=f"æ•¸å€¼å‹ç‰¹å¾µ"
                    )
            
            col_idx += 1
        
        submitted = st.form_submit_button("åŸ·è¡Œé æ¸¬", use_container_width=True)
        
        if submitted:
            # æ¸…é™¤èˆŠçš„é æ¸¬çµæœï¼ˆä¿®å¾©åˆ·æ–°å•é¡Œï¼‰
            if 'prediction_result' in st.session_state:
                del st.session_state['prediction_result']
            if 'prediction_error' in st.session_state:
                del st.session_state['prediction_error']
            if 'prediction_warning' in st.session_state:
                del st.session_state['prediction_warning']
            if 'prediction_calculation' in st.session_state:
                del st.session_state['prediction_calculation']
            
            # æ¸…é™¤æ‰€æœ‰é©—ç®—ç›¸é—œçš„ session state
            keys_to_remove = [key for key in st.session_state.keys() if key.startswith('calc_')]
            for key in keys_to_remove:
                del st.session_state[key]
            
            # å°‡è¼¸å…¥è³‡æ–™è½‰æ›ç‚º DataFrame
            input_df = pd.DataFrame([input_data])
            
            # é©—è­‰è¼¸å…¥è³‡æ–™
            is_valid, error_msg, validation_info = validate_prediction_input(input_df, model)
            
            if not is_valid:
                st.session_state['prediction_error'] = error_msg
                st.session_state['prediction_result'] = None
            else:
                # æª¢æŸ¥ä¸¦æ’é™¤ç›®æ¨™è®Šæ•¸ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                target_names = model.target_names or []
                if target_names:
                    target_vars_in_input = [col for col in input_df.columns if col in target_names]
                    if target_vars_in_input:
                        st.session_state['prediction_warning'] = (
                            f"âš ï¸ æ³¨æ„ï¼šè¼¸å…¥è³‡æ–™åŒ…å«ç›®æ¨™è®Šæ•¸æ¬„ä½ï¼ˆ{', '.join(target_vars_in_input)}ï¼‰ï¼Œ"
                            f"é€™äº›æ¬„ä½å°‡è¢«è‡ªå‹•æ’é™¤ï¼Œä¸æœƒç”¨æ–¼é æ¸¬ã€‚"
                        )
                        input_df = input_df.drop(columns=target_vars_in_input)
                    else:
                        st.session_state['prediction_warning'] = None
                
                # åŸ·è¡Œé æ¸¬
                try:
                    with st.spinner("æ­£åœ¨åŸ·è¡Œé æ¸¬..."):
                        predictions = model.predict(input_df)
                    
                    # åˆä½µè¼¸å…¥å’Œé æ¸¬çµæœ
                    result_df = pd.concat([input_df, predictions], axis=1)
                    
                    # ä¿å­˜çµæœåˆ° session state
                    st.session_state['prediction_result'] = {
                        'input_df': input_df,
                        'predictions': predictions,
                        'result_df': result_df
                    }
                    st.session_state['prediction_error'] = None
                    
                except Exception as e:
                    st.session_state['prediction_error'] = f"âŒ é æ¸¬å¤±æ•—ï¼š{str(e)}"
                    st.session_state['prediction_result'] = None
    
    # åœ¨è¡¨å–®å¤–éƒ¨é¡¯ç¤ºé æ¸¬çµæœ
    if 'prediction_error' in st.session_state and st.session_state['prediction_error']:
        st.error(st.session_state['prediction_error'])
    
    if 'prediction_warning' in st.session_state and st.session_state['prediction_warning']:
        st.warning(st.session_state['prediction_warning'])
    
    if 'prediction_result' in st.session_state and st.session_state['prediction_result'] is not None:
        result = st.session_state['prediction_result']
        
        st.success("âœ… é æ¸¬å®Œæˆï¼")
        
        # é¡¯ç¤ºé æ¸¬çµæœ
        st.markdown("### é æ¸¬çµæœ")
        
        # é¡¯ç¤ºè¼¸å…¥è³‡æ–™
        st.markdown("#### è¼¸å…¥è³‡æ–™")
        st.dataframe(result['input_df'], use_container_width=True)
        
        # é¡¯ç¤ºé æ¸¬å€¼
        st.markdown("#### é æ¸¬å€¼")
        
        # é¡¯ç¤ºé æ¸¬å€¼è¡¨æ ¼
        st.dataframe(result['predictions'], use_container_width=True)
        
        # ç‚ºæ¯å€‹é æ¸¬å€¼æ·»åŠ é©—ç®—åŠŸèƒ½
        for target_col in result['predictions'].columns:
            pred_value = result['predictions'][target_col].iloc[0]
            
            # ä½¿ç”¨ expander é¡¯ç¤ºé©—ç®—éç¨‹ï¼ˆé è¨­å±•é–‹ï¼‰
            with st.expander(f"ğŸ” {target_col} é©—ç®—éç¨‹ï¼ˆé»æ“Šå±•é–‹/æ”¶èµ·ï¼‰", expanded=False):
                try:
                    calc_result = calculate_manual_prediction(model, result['input_df'], target_col)
                    
                    if calc_result.get('can_calculate', False):
                        st.markdown("##### ğŸ“ è¨ˆç®—å…¬å¼")
                        st.code(f"é æ¸¬å€¼ = æˆªè· + Î£(ä¿‚æ•¸ Ã— ç‰¹å¾µå€¼)")
                        
                        st.markdown("##### ğŸ“Š è¨ˆç®—æ­¥é©Ÿ")
                        for step in calc_result['calculation_steps']:
                            st.markdown(step)
                        
                        st.markdown("##### âœ… é©—è­‰")
                        model_pred = pred_value
                        manual_pred = calc_result['manual_prediction']
                        diff = abs(model_pred - manual_pred)
                        
                        col_a, col_b, col_c = st.columns(3)
                        with col_a:
                            st.metric("æ¨¡å‹é æ¸¬å€¼", f"{model_pred:.6f}")
                        with col_b:
                            st.metric("æ‰‹å‹•è¨ˆç®—å€¼", f"{manual_pred:.6f}")
                        with col_c:
                            st.metric("å·®ç•°", f"{diff:.10f}")
                        
                        if diff < 1e-6:
                            st.success("âœ… é©—ç®—é€šéï¼æ¨¡å‹é æ¸¬å€¼èˆ‡æ‰‹å‹•è¨ˆç®—å€¼ä¸€è‡´ã€‚")
                        else:
                            st.warning(f"âš ï¸ å·®ç•°è¼ƒå¤§ï¼ˆ{diff:.10f}ï¼‰ï¼Œå¯èƒ½ç”±æ–¼æ•¸å€¼ç²¾åº¦æˆ–æ¨¡å‹å¯¦ç¾å·®ç•°ã€‚")
                    else:
                        st.info(f"â„¹ï¸ {calc_result.get('message', 'ç„¡æ³•é€²è¡Œé©—ç®—')}")
                except Exception as e:
                    st.error(f"âŒ é©—ç®—éç¨‹å‡ºéŒ¯ï¼š{str(e)}")
                    import traceback
                    with st.expander("æŸ¥çœ‹è©³ç´°éŒ¯èª¤è³‡è¨Š"):
                        st.code(traceback.format_exc())
        
        # æä¾›ä¸‹è¼‰åŠŸèƒ½
        csv = result['result_df'].to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰é æ¸¬çµæœ (CSV)",
            data=csv,
            file_name="prediction_result.csv",
            mime="text/csv"
        )

else:  # CSV æª”æ¡ˆæ‰¹æ¬¡é æ¸¬
    st.markdown("### æ­¥é©Ÿ 3: ä¸Šå‚³ CSV æª”æ¡ˆä¸¦é æ¸¬")
    
    uploaded_file = st.file_uploader(
        "ä¸Šå‚³ CSV æª”æ¡ˆ",
        type=['csv'],
        help="è«‹ä¸Šå‚³èˆ‡è¨“ç·´è³‡æ–™ç›¸åŒæ ¼å¼çš„ CSV æª”æ¡ˆ"
    )
    
    if uploaded_file is not None:
        # è¼‰å…¥ CSV æª”æ¡ˆ
        with st.spinner("æ­£åœ¨è¼‰å…¥ CSV æª”æ¡ˆ..."):
            input_df, error_message = load_csv_file(uploaded_file)
        
        if error_message:
            st.error(f"âŒ {error_message}")
            st.stop()
        
        if input_df is None:
            st.error("âŒ ç„¡æ³•è®€å–æª”æ¡ˆ")
            st.stop()
        
        # é©—è­‰ DataFrame
        is_valid, validation_error = validate_dataframe(input_df)
        if not is_valid:
            st.error(f"âŒ {validation_error}")
            st.stop()
        
        st.success(f"âœ… CSV æª”æ¡ˆè¼‰å…¥æˆåŠŸï¼ï¼ˆ{input_df.shape[0]} ç­†ï¼Œ{input_df.shape[1]} æ¬„ä½ï¼‰")
        
        # é¡¯ç¤ºè³‡æ–™é è¦½
        st.markdown("#### è³‡æ–™é è¦½")
        st.dataframe(input_df.head(10), use_container_width=True)
        
        # é©—è­‰è¼¸å…¥è³‡æ–™
        st.markdown("#### è³‡æ–™é©—è­‰")
        is_valid, error_msg, validation_info = validate_prediction_input(input_df, model)
        
        if not is_valid:
            st.error(f"âŒ è³‡æ–™é©—è­‰å¤±æ•—ï¼š{error_msg}")
            if validation_info and 'valid_categories' in validation_info:
                st.info("ğŸ’¡ æç¤ºï¼šè«‹ç¢ºèªé¡åˆ¥å‹ç‰¹å¾µçš„å€¼åœ¨æœ‰æ•ˆå€¼ç¯„åœå…§")
        else:
            # æª¢æŸ¥ä¸¦æ’é™¤ç›®æ¨™è®Šæ•¸ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            target_names = model.target_names or []
            if target_names:
                target_vars_in_input = [col for col in input_df.columns if col in target_names]
                if target_vars_in_input:
                    st.warning(
                        f"âš ï¸ æ³¨æ„ï¼šCSV æª”æ¡ˆåŒ…å«ç›®æ¨™è®Šæ•¸æ¬„ä½ï¼ˆ{', '.join(target_vars_in_input)}ï¼‰ï¼Œ"
                        f"é€™äº›æ¬„ä½å°‡è¢«è‡ªå‹•æ’é™¤ï¼Œä¸æœƒç”¨æ–¼é æ¸¬ã€‚"
                    )
                    input_df = input_df.drop(columns=target_vars_in_input)
            
            st.success("âœ… è³‡æ–™é©—è­‰é€šéï¼")
            
            # åŸ·è¡Œæ‰¹æ¬¡é æ¸¬
            if st.button("åŸ·è¡Œæ‰¹æ¬¡é æ¸¬", use_container_width=True, type="primary"):
                try:
                    # é™åˆ¶æ‰¹æ¬¡å¤§å°ï¼ˆé¿å…è¨˜æ†¶é«”å•é¡Œï¼‰
                    max_batch_size = 10000
                    if len(input_df) > max_batch_size:
                        st.warning(f"âš ï¸ è³‡æ–™é‡è¼ƒå¤§ï¼ˆ{len(input_df)} ç­†ï¼‰ï¼Œå°‡åˆ†æ‰¹è™•ç†ï¼ˆæ¯æ‰¹ {max_batch_size} ç­†ï¼‰")
                        
                        all_predictions = []
                        progress_bar = st.progress(0)
                        
                        for i in range(0, len(input_df), max_batch_size):
                            batch_df = input_df.iloc[i:i+max_batch_size]
                            batch_predictions = model.predict(batch_df)
                            all_predictions.append(batch_predictions)
                            
                            progress = min((i + max_batch_size) / len(input_df), 1.0)
                            progress_bar.progress(progress)
                        
                        predictions = pd.concat(all_predictions, ignore_index=True)
                        progress_bar.empty()
                    else:
                        with st.spinner("æ­£åœ¨åŸ·è¡Œæ‰¹æ¬¡é æ¸¬..."):
                            predictions = model.predict(input_df)
                    
                    st.success(f"âœ… æ‰¹æ¬¡é æ¸¬å®Œæˆï¼ï¼ˆå…± {len(predictions)} ç­†ï¼‰")
                    
                    # é¡¯ç¤ºé æ¸¬çµæœ
                    st.markdown("### é æ¸¬çµæœ")
                    
                    # åˆä½µåŸå§‹è³‡æ–™å’Œé æ¸¬çµæœ
                    result_df = pd.concat([input_df.reset_index(drop=True), predictions.reset_index(drop=True)], axis=1)
                    
                    # é¡¯ç¤ºçµæœè¡¨æ ¼
                    st.dataframe(result_df, use_container_width=True, height=400)
                    
                    # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
                    st.markdown("#### é æ¸¬çµæœçµ±è¨ˆ")
                    for target in predictions.columns:
                        st.write(f"**{target}**ï¼š")
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("å¹³å‡å€¼", f"{predictions[target].mean():.4f}")
                        with col2:
                            st.metric("æ¨™æº–å·®", f"{predictions[target].std():.4f}")
                        with col3:
                            st.metric("æœ€å°å€¼", f"{predictions[target].min():.4f}")
                        st.metric("æœ€å¤§å€¼", f"{predictions[target].max():.4f}")
                    
                    # æä¾›ä¸‹è¼‰åŠŸèƒ½
                    csv = result_df.to_csv(index=False).encode('utf-8-sig')
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰é æ¸¬çµæœ (CSV)",
                        data=csv,
                        file_name="batch_prediction_results.csv",
                        mime="text/csv"
                    )
                    
                except Exception as e:
                    st.error(f"âŒ é æ¸¬å¤±æ•—ï¼š{str(e)}")
                    import traceback
                    with st.expander("æŸ¥çœ‹è©³ç´°éŒ¯èª¤è³‡è¨Š"):
                        st.code(traceback.format_exc())
